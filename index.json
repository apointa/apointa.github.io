[{"authors":null,"categories":null,"content":"About me\nHi, I am Andreas. I am a PhD student in the field of Machine Learning at the Institute for Machine Learning at Johannes Kepler University, Linz, Austria, in the Team of Sepp Hochreiter. I am also part of the ELLIS PhD Program. Previously, I completed my bachelor’s and master’s degrees in Computer Science at the Technical University of Vienna.\nIn my research I am most interested in Deep Learning in the context of Time Series or more broadly said — sequential data. Besides my PhDs focus and motivated by my previous studies (I did a fair amount of Symbolic AI in my bachelor’s and master’s) and side study (Economics), I am also generally interested in Neuro-Symbolic approaches and in applications in economics/finance.\nI have also some experience as professional Software Developer and I believe that readable code is as important as readable papers.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"About me\nHi, I am Andreas. I am a PhD student in the field of Machine Learning at the Institute for Machine Learning at Johannes Kepler University, Linz, Austria, in the Team of Sepp Hochreiter.","tags":null,"title":"Andreas Auer","type":"authors"},{"authors":["Maximilian Beck, Korbinian Pöppel, Markus Spanring, **Andreas Auer**, Oleksandra Prudnikova, Michael Kopp, Günter Klambauer, Johannes Brandstetter, Sepp Hochreiter "],"categories":null,"content":"","date":171504e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":171504e4,"objectID":"0b93749f7cee46a934f2a8450e8478db","permalink":"https://apointa.github.io/publication/2024-xlstm.html","publishdate":"2024-05-07T00:00:00Z","relpermalink":"/publication/2024-xlstm.html","section":"publication","summary":"In the 1990s, the constant error carousel and gating were introduced as the central ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have stood the test of time and contributed to numerous deep learning success stories, in particular they constituted the first Large Language Models (LLMs). However, the advent of the Transformer technology with parallelizable self-attention at its core marked the dawn of a new era, outpacing LSTMs at scale. We now raise a simple question: How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs? Firstly, we introduce exponential gating with appropriate normalization and stabilization techniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM with a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that is fully parallelizable with a matrix memory and a covariance update rule. Integrating these LSTM extensions into residual block backbones yields xLSTM blocks that are then residually stacked into xLSTM architectures. Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to state-of-the-art Transformers and State Space Models, both in performance and scaling.","tags":null,"title":"xLSTM: Extended Long Short-Term Memory","type":"publication"},{"authors":["**Andreas Auer**, Martin Gauch, Frederik Kratzert, Grey Nearing, Sepp Hochreiter, Daniel Klotz "],"categories":null,"content":"","date":1710374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1710374400,"objectID":"3416988e5a2770926d749c7b1155f48a","permalink":"https://apointa.github.io/publication/2024-data-centric.html","publishdate":"2024-03-14T00:00:00Z","relpermalink":"/publication/2024-data-centric.html","section":"publication","summary":"Uncertainty estimates are fundamental to assess the reliability of predictive models in hydrology. We use the framework of Conformal Prediction to investigate the impact of temporal and spatial information on uncertainty estimates within hydrological predictions. Integrating recent information significantly enhances overall uncertainty predictions, even with substantial gaps between updates. While local information yields good results on average, it proves insufficient for peak flow predictions. Incorporating global information improves the accuracy of peak flow bounds, corroborating findings from related studies. Overall, the study underscores the importance of continuous data updates and the integration of global information for robust and efficient uncertainty estimation.","tags":null,"title":"A data-centric perspective on the information needed for hydrological uncertainty predictions","type":"publication"},{"authors":null,"categories":null,"content":"Test\n","date":1682294400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682294400,"objectID":"a958a57ca9780c2aa77d75e59c0581c0","permalink":"https://apointa.github.io/news/page-created.html","publishdate":"2023-04-24T00:00:00Z","relpermalink":"/news/page-created.html","section":"news","summary":"I have a page now!","tags":null,"title":"I have a page now!","type":"news"},{"authors":["**Andreas Auer**, Martin Gauch, Daniel Klotz, Sepp Hochreiter "],"categories":null,"content":"","date":1679443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679443200,"objectID":"d89cbee4df478c4196dde0449e8bcc92","permalink":"https://apointa.github.io/publication/2023-hopcpt.html","publishdate":"2023-03-22T00:00:00Z","relpermalink":"/publication/2023-hopcpt.html","section":"publication","summary":"To quantify uncertainty, conformal prediction methods are gaining continuously more interest and have already been successfully applied to various domains. However, they are difficult to apply to time series as the autocorrelative structure of time series violates basic assumptions required by conformal prediction. We propose HopCPT, a novel conformal prediction approach for time series that not only copes with temporal structures but leverages them. We show that our approach is theoretically well justified for time series where temporal dependencies are present. In experiments, we demonstrate that our new approach outperforms state-of-the-art conformal prediction methods on multiple real-world time series datasets from four different domains.","tags":null,"title":"Conformal Prediction for Time Series with Modern Hopfield Networks","type":"publication"},{"authors":["**Andreas Auer**"],"categories":null,"content":"","date":1647561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647561600,"objectID":"74e62915525e19aa733e2ee6f18131b4","permalink":"https://apointa.github.io/publication/2022-vtkgnn.html","publishdate":"2022-03-18T00:00:00Z","relpermalink":"/publication/2022-vtkgnn.html","section":"publication","summary":"Temporal Knowledge Graphs, a form of a graph-structured knowledge bases, gained increased interest in both academia and industry in the last years. Most Knowledge Graphs suffer from incompleteness, ie from facts which are valid in the real world that are not represented in the Knowledge Graph at hand. A set of methods to counter this problem are Knowledge Graph Embeddings, which learn vector embeddings for the knowledge graph elements in a way that the underlying structure of the Knowledge Graph is preserved and utilize the learned embeddings to predict missing facts. Knowledge Graph Embeddings show good results but allow only transductive link prediction. In addition their integration of prior information of the entities as well as of temporal information is insufficient and they suffer from scalability problems for large graphs. In this thesis we propose the temporal knowledge graph neural network VT-KGNN. The model overcomes the limitations of Knowledge Graph Embeddings by using a multirelational adaption of local message passing graph neural networks as encoder and a Knowledge Graph Embedding score function as decoder. VT-KGNN especially focuses on the integration of temporal facts, more concretely on facts annotated with a valid time. It does not rely on snapshots but utilizes the temporal information by directly encoding it as a feature used in the Graph Neural Network. The model considers the start and end time of a fact individually, as well as in combination in the form of its duration. In addition it can utilize temporal relationships between facts that share entities","tags":null,"title":"VT-KGNN: A Valid Time Knowledge Graph Neural Network","type":"publication"}]